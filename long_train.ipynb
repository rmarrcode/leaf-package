{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing _core module...\n",
      "_core module initialization complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "import time\n",
    "import wandb\n",
    "#\n",
    "from leaf._core import LeafConfig, LeafTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LeafConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.add_server(\n",
    "    server_name=\"gpu-server-1\",\n",
    "    username=\"root\",\n",
    "    hostname=\"174.93.255.152\",\n",
    "    port=40056,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.add_server(\n",
    "#     server_name=\"gpu-server-1\",\n",
    "#     username=\"root\",\n",
    "#     hostname=\"120.238.149.138\",\n",
    "#     port=39363,  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Available Servers and Resources ===\n",
      "\n",
      "==================================================\n",
      "Server: gpu-server-1\n",
      "==================================================\n",
      "Status: Not connected\n",
      "Type: Remote server\n",
      "Username: root\n",
      "Hostname: 184.145.155.117\n",
      "Port: 26765\n",
      "\n",
      "No computational resources found\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Server: localhost\n",
      "==================================================\n",
      "Status: Connected\n",
      "Type: Local machine\n",
      "\n",
      "Available Resources (1):\n",
      "--------------------------------------------------\n",
      "\n",
      "Resource 1:\n",
      "  Name: Apple M1\n",
      "  Type: CPU\n",
      "  Properties:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== End of Server List ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config.print_all_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_trainer = LeafTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing get_gradients_from_server with hardcoded values ===\n",
      "\n",
      "============================================================\n",
      "Testing server: gpu-server-1\n",
      "============================================================\n",
      "Debug: Server gpu-server-1 has hostname: 184.145.155.117 and port: 26765\n",
      "Server type: Remote\n",
      "Connection status: Not connected\n",
      "Skipping server gpu-server-1 - not connected\n",
      "\n",
      "============================================================\n",
      "Testing server: localhost\n",
      "============================================================\n",
      "Debug: Server localhost has hostname:  and port: 0\n",
      "Server type: Local\n",
      "Connection status: Connected\n",
      "  Computing gradients locally (using GetGradients from server_communication)...\n",
      "  Local computation completed\n",
      "✓ Gradient computation successful!\n",
      "  Loss: 0.5\n",
      "  Gradients size: 3 elements\n",
      "  Sample gradients: 4.59312e+27, 4.58281e+30, 6.88852e+22\n",
      "\n",
      "============================================================\n",
      "Gradient testing with hardcoded values completed!\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'server_results': [{'server_name': 'gpu-server-1',\n",
       "   'is_local': False,\n",
       "   'is_connected': False,\n",
       "   'success': False,\n",
       "   'error': 'Server not connected'},\n",
       "  {'server_name': 'localhost',\n",
       "   'is_local': True,\n",
       "   'is_connected': True,\n",
       "   'success': True,\n",
       "   'loss': 0.5,\n",
       "   'gradients_size': 3,\n",
       "   'gradients': [4.593116492825124e+27,\n",
       "    4.582813224188066e+30,\n",
       "    6.888519090641375e+22]}],\n",
       " 'total_servers': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_trainer.test_with_hardcoded_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                     download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                       shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanmarr/Documents/Subnautica_mod/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ryanmarr/Documents/Subnautica_mod/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-50 and modify for CIFAR-10\n",
    "model = resnet50(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()  # Remove maxpool as CIFAR-10 images are small\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # Change output to 10 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(\n",
    "#     project=\"big-model-example\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for idx, (input, target) in enumerate(trainloader):\n",
    "    print(idx)\n",
    "    if idx == 0:\n",
    "        i = input\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.2078, -1.1497, -1.0721,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-1.2660, -0.9946, -0.6263,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-1.4211, -1.2466, -0.7813,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          ...,\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291]],\n",
       "\n",
       "         [[-1.3956, -1.3366, -1.2382,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-1.4742, -1.2579, -0.9629,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-1.6316, -1.4546, -1.0809,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          ...,\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183]],\n",
       "\n",
       "         [[-1.7336, -1.6166, -1.4995,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-1.7727, -1.6556, -1.4215,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-1.9092, -1.7336, -1.4020,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          ...,\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214]]],\n",
       "\n",
       "\n",
       "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          ...,\n",
       "          [-2.4291, -2.4291, -0.0835,  ...,  0.4981,  0.4787,  0.2848],\n",
       "          [-2.4291, -2.4291,  0.3430,  ...,  0.2267,  0.1685,  0.2461],\n",
       "          [-2.4291, -2.4291,  0.1879,  ...,  0.1491,  0.0522, -0.0641]],\n",
       "\n",
       "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          ...,\n",
       "          [-2.4183, -2.4183, -0.3532,  ...,  0.1581,  0.1384, -0.0386],\n",
       "          [-2.4183, -2.4183,  0.0794,  ..., -0.1369, -0.1959, -0.0976],\n",
       "          [-2.4183, -2.4183, -0.0976,  ..., -0.1959, -0.2746, -0.3532]],\n",
       "\n",
       "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          ...,\n",
       "          [-2.2214, -2.2214, -0.6411,  ..., -0.2509, -0.2899, -0.4460],\n",
       "          [-2.2214, -2.2214, -0.2118,  ..., -0.4655, -0.5825, -0.4655],\n",
       "          [-2.2214, -2.2214, -0.4460,  ..., -0.5045, -0.6020, -0.6801]]],\n",
       "\n",
       "\n",
       "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          ...,\n",
       "          [ 1.9325,  2.0876,  2.2427,  ...,  0.1685, -2.4291, -2.4291],\n",
       "          [ 1.9132,  2.0876,  2.1652,  ...,  0.0910, -2.4291, -2.4291],\n",
       "          [ 1.8550,  2.0101,  1.9907,  ...,  0.4981, -2.4291, -2.4291]],\n",
       "\n",
       "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          ...,\n",
       "          [ 1.3774,  1.5544,  1.6724,  ..., -0.4319, -2.4183, -2.4183],\n",
       "          [ 1.3578,  1.5741,  1.6331,  ..., -0.7859, -2.4183, -2.4183],\n",
       "          [ 1.2791,  1.5151,  1.4758,  ..., -0.6679, -2.4183, -2.4183]],\n",
       "\n",
       "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          ...,\n",
       "          [ 1.2319,  1.4075,  1.4856,  ..., -0.0753, -2.2214, -2.2214],\n",
       "          [ 1.2709,  1.4661,  1.4856,  ..., -0.4069, -2.2214, -2.2214],\n",
       "          [ 1.2514,  1.4465,  1.3490,  ..., -0.2704, -2.2214, -2.2214]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          ...,\n",
       "          [ 0.7307,  0.5174, -0.3936,  ...,  0.2654,  0.1879, -2.4291],\n",
       "          [ 0.6919,  0.6919,  0.5174,  ...,  0.5368,  0.3430, -2.4291],\n",
       "          [ 1.6418,  0.4399,  0.2461,  ...,  0.5174,  0.3624, -2.4291]],\n",
       "\n",
       "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          ...,\n",
       "          [ 0.6301,  0.4728, -0.5302,  ..., -0.2352, -0.1172, -2.4183],\n",
       "          [ 0.5514,  0.4924,  0.3351,  ...,  0.1581,  0.0401, -2.4183],\n",
       "          [ 1.4758,  0.1581, -0.0189,  ...,  0.2958,  0.1188, -2.4183]],\n",
       "\n",
       "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          ...,\n",
       "          [ 0.7052,  0.5296, -0.3874,  ..., -0.2509, -0.0753, -2.2214],\n",
       "          [ 0.6466,  0.6076,  0.4710,  ...,  0.1784,  0.1198, -2.2214],\n",
       "          [ 1.6416,  0.3540,  0.0808,  ...,  0.3345,  0.2564, -2.2214]]],\n",
       "\n",
       "\n",
       "        [[[-2.4291, -2.4291, -2.4291,  ...,  1.5642,  1.5836,  1.6030],\n",
       "          [-2.4291, -2.4291, -2.4291,  ...,  1.5642,  1.6030,  1.6030],\n",
       "          [-2.4291, -2.4291, -2.4291,  ...,  1.5642,  1.6030,  1.6030],\n",
       "          ...,\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -1.0721, -1.4986, -1.5180],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -1.1690, -1.4986, -1.5567],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291]],\n",
       "\n",
       "         [[-2.4183, -2.4183, -2.4183,  ...,  1.6331,  1.6528,  1.6724],\n",
       "          [-2.4183, -2.4183, -2.4183,  ...,  1.6331,  1.6724,  1.6724],\n",
       "          [-2.4183, -2.4183, -2.4183,  ...,  1.6331,  1.6724,  1.6724],\n",
       "          ...,\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -1.0612, -1.4939, -1.5136],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -1.1596, -1.4939, -1.5529],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183]],\n",
       "\n",
       "         [[-2.2214, -2.2214, -2.2214,  ...,  1.7977,  1.8172,  1.8367],\n",
       "          [-2.2214, -2.2214, -2.2214,  ...,  1.7977,  1.8367,  1.8367],\n",
       "          [-2.2214, -2.2214, -2.2214,  ...,  1.7977,  1.8367,  1.8367],\n",
       "          ...,\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -0.7581, -1.1873, -1.2069],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -0.8557, -1.1873, -1.2459],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214]]],\n",
       "\n",
       "\n",
       "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
       "          ...,\n",
       "          [-0.8201, -0.8589, -0.6844,  ..., -2.0995, -2.0608, -2.4291],\n",
       "          [-0.7426, -0.7038, -0.0060,  ..., -1.9444, -1.6537, -2.4291],\n",
       "          [-0.6263, -0.0835,  0.2848,  ..., -1.5761, -0.9946, -2.4291]],\n",
       "\n",
       "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
       "          ...,\n",
       "          [-0.7269, -0.7269, -0.5499,  ..., -1.8873, -1.8873, -2.4183],\n",
       "          [-0.6679, -0.5696,  0.0794,  ..., -1.7299, -1.4939, -2.4183],\n",
       "          [-0.5499,  0.0401,  0.3548,  ..., -1.4152, -0.8646, -2.4183]],\n",
       "\n",
       "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
       "          ...,\n",
       "          [-0.7581, -0.7581, -0.4069,  ..., -1.7141, -1.7141, -2.2214],\n",
       "          [-0.6801, -0.5240,  0.3735,  ..., -1.5971, -1.3434, -2.2214],\n",
       "          [-0.5435,  0.1198,  0.6466,  ..., -1.3044, -0.7386, -2.2214]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model with LeafTrainer...\n",
      "Model state extracted, size: 23574015 parameters\n",
      "Distributing model to 2 servers...\n",
      "Debug: Server gpu-server-1 has hostname: 184.145.155.117 and port: 26765\n",
      "Skipping server gpu-server-1 - not connected\n",
      "Debug: Server localhost has hostname:  and port: 0\n",
      "Storing model on server: localhost\n",
      "✓ Model stored locally successfully\n",
      "Model registered successfully! Total models: 1\n"
     ]
    }
   ],
   "source": [
    "model = leaf_trainer.register_model(model)\n",
    "#input, target = trainloader[0]\n",
    "# criterion = leaf_trainer.register_criterion(criterion)\n",
    "# optimizer = leaf_trainer.register_optimizer(optimizer)\n",
    "\n",
    "# outputs = model(input)\n",
    "# loss = criterion(outputs=outputs, target=target)\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43masdf\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Batch: {batch_idx + 1} | Loss: {running_loss/(batch_idx + 1):.3f} | '\n",
    "                  f'Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    return running_loss/len(trainloader), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return test_loss/len(testloader), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "print('Starting training...')\n",
    "best_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train()\n",
    "    test_loss, test_acc = test()\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    print(f'\\nEpoch: {epoch + 1}/{num_epochs}')\n",
    "    print(f'Time: {time.time() - start_time:.2f}s')\n",
    "    print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        print('Saving best model...')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': test_acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        torch.save(state, 'best_model.pth')\n",
    "        best_acc = test_acc\n",
    "print('Training completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
