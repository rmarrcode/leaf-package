{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing _core module...\n",
      "_core module initialization complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "import time\n",
    "import wandb\n",
    "#\n",
    "from leaf._core import LeafConfig, LeafTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LeafConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH connection test successful\n",
      "174.93.255.152 : ssh connection successful\n",
      "Checking for Docker installation...\n",
      "174.93.255.152 :docker verification successful\n",
      "174.93.255.152 : docker daemon verification successful\n",
      "Docker files copied successfully\n",
      "174.93.255.152 : docker files copied successful\n",
      "leaf-grpc-server\n",
      "Building Docker image...\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 1.52kB done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/ubuntu:22.04\n",
      "#2 DONE 0.3s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [builder  1/11] FROM docker.io/library/ubuntu:22.04@sha256:3c61d3759c2639d4b836d32a2d3c83fa0214e36f195a3421018dbaaf79cbe37f\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 20.33kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [builder  3/11] RUN pip3 install pybind11\n",
      "#6 CACHED\n",
      "\n",
      "#7 [builder  4/11] WORKDIR /src\n",
      "#7 CACHED\n",
      "\n",
      "#8 [builder  5/11] COPY server_communication.cpp .\n",
      "#8 CACHED\n",
      "\n",
      "#9 [builder  9/11] COPY model.cpp .\n",
      "#9 CACHED\n",
      "\n",
      "#10 [builder  7/11] COPY server_communication.proto .\n",
      "#10 CACHED\n",
      "\n",
      "#11 [builder  2/11] RUN apt-get update && apt-get install -y     build-essential     protobuf-compiler-grpc     libgrpc++-dev     libprotobuf-dev     python3-dev     python3-pip     && rm -rf /var/lib/apt/lists/*\n",
      "#11 CACHED\n",
      "\n",
      "#12 [builder  6/11] COPY server_communication.h .\n",
      "#12 CACHED\n",
      "\n",
      "#13 [builder  8/11] COPY model.h .\n",
      "#13 CACHED\n",
      "\n",
      "#14 [builder 10/11] RUN protoc --cpp_out=. --grpc_out=. --plugin=protoc-gen-grpc=/usr/bin/grpc_cpp_plugin server_communication.proto\n",
      "#14 CACHED\n",
      "\n",
      "#15 [builder 11/11] RUN g++ -std=c++17 -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include server_communication.cpp model.cpp server_communication.pb.cc server_communication.grpc.pb.cc -lgrpc++ -lprotobuf -lpython3.10 -o server_communication && echo \"Compilation successful\" && ls -la server_communication\n",
      "#15 2.103 In file included from server_communication.h:6,\n",
      "#15 2.103                  from server_communication.cpp:7:\n",
      "#15 2.103 model.h:15:7: warning: 'Model' declared with greater visibility than the type of its field 'Model::pytorch_model' [-Wattributes]\n",
      "#15 2.103    15 | class Model {\n",
      "#15 2.103       |       ^~~~~\n",
      "#15 2.103 model.h:15:7: warning: 'Model' declared with greater visibility than the type of its field 'Model::stored_outputs' [-Wattributes]\n",
      "#15 2.103 model.h:15:7: warning: 'Model' declared with greater visibility than the type of its field 'Model::loss' [-Wattributes]\n",
      "#15 4.757 In file included from model.cpp:1:\n",
      "#15 4.757 model.h:15:7: warning: 'Model' declared with greater visibility than the type of its field 'Model::pytorch_model' [-Wattributes]\n",
      "#15 4.757    15 | class Model {\n",
      "#15 4.757       |       ^~~~~\n",
      "#15 4.757 model.h:15:7: warning: 'Model' declared with greater visibility than the type of its field 'Model::stored_outputs' [-Wattributes]\n",
      "#15 4.757 model.h:15:7: warning: 'Model' declared with greater visibility than the type of its field 'Model::loss' [-Wattributes]\n",
      "#15 9.480 Compilation successful\n",
      "#15 9.483 -rwxr-xr-x 1 root root 1482856 Jul  8 06:36 server_communication\n",
      "#15 DONE 9.5s\n",
      "\n",
      "#16 [stage-1 4/6] WORKDIR /app\n",
      "#16 CACHED\n",
      "\n",
      "#17 [stage-1 2/6] RUN apt-get update && apt-get install -y     libgrpc++1     libgrpc10     libprotobuf23     python3     python3-pip     && rm -rf /var/lib/apt/lists/*\n",
      "#17 CACHED\n",
      "\n",
      "#18 [stage-1 3/6] RUN pip3 install pybind11\n",
      "#18 CACHED\n",
      "\n",
      "#19 [stage-1 5/6] COPY --from=builder /src/server_communication ./server_communication\n",
      "#19 CACHED\n",
      "\n",
      "#20 [stage-1 6/6] RUN chmod +x server_communication\n",
      "#20 CACHED\n",
      "\n",
      "#21 exporting to image\n",
      "#21 exporting layers done\n",
      "#21 writing image sha256:90a03ae68db48e6babb13e1d57b3058f329a1b1cf18003b464f47d65e9ffd849 done\n",
      "#21 naming to docker.io/library/leaf-grpc-server done\n",
      "#21 DONE 0.0s\n",
      "Docker build successful, starting container...\n",
      "d37e5c73641461756626b655a9ed3a55dd71ba73123beca139b18c4dbb632c1a\n",
      "Container is running. Checking logs...\n",
      "Testing if gRPC server is responding...\n",
      "gRPC server is responding\n",
      "Docker container started successfully!\n",
      "d37e5c736414   leaf-grpc-server   \"./server_communicat…\"   12 seconds ago   Up 11 seconds   127.0.0.1:50051->50051/tcp   leaf-grpc-server\n",
      "174.93.255.152 : docker container built successful\n",
      "SSH tunnel established on port 50052 (PID: 29121)\n",
      "174.93.255.152 : ssh tunnel setup successful\n",
      "174.93.255.152 : grpc connection successful\n",
      "gRPC verification successful\n"
     ]
    }
   ],
   "source": [
    "config.add_server(\n",
    "    server_name=\"gpu-server-1\",\n",
    "    username=\"root\",\n",
    "    hostname=\"174.93.255.152\",\n",
    "    port=56442,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_trainer = LeafTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Available Servers and Resources ===\n",
      "\n",
      "==================================================\n",
      "Server: gpu-server-1\n",
      "==================================================\n",
      "Status: Connected\n",
      "Type: Remote server\n",
      "Username: root\n",
      "Hostname: 174.93.255.152\n",
      "Port: 56442\n",
      "\n",
      "Available Resources (1):\n",
      "--------------------------------------------------\n",
      "\n",
      "Resource 1:\n",
      "  Name: Quadro P4000\n",
      "  Type: GPU\n",
      "  Properties:\n",
      "    free_memory: 8105 MiB\n",
      "\n",
      "    total_memory: 8192 MiB\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Server: localhost\n",
      "==================================================\n",
      "Status: Connected\n",
      "Type: Local machine\n",
      "\n",
      "Available Resources (1):\n",
      "--------------------------------------------------\n",
      "\n",
      "Resource 1:\n",
      "  Name: Apple M1\n",
      "  Type: CPU\n",
      "  Properties:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== End of Server List ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config.print_all_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_trainer = LeafTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing get_gradients_from_server with hardcoded values ===\n",
      "\n",
      "============================================================\n",
      "Testing server: gpu-server-1\n",
      "============================================================\n",
      "Debug: Server gpu-server-1 has hostname: 174.93.255.152 and port: 56442\n",
      "Server type: Remote\n",
      "Connection status: Connected\n",
      "Creating gRPC channel for server 'gpu-server-1' at address: localhost:50052\n",
      "✓ Gradient computation successful!\n",
      "  Loss: 0.5\n",
      "  Gradients size: 3 elements\n",
      "  Sample gradients: 4.59312e+27, 4.58281e+30, 6.88852e+22\n",
      "\n",
      "============================================================\n",
      "Testing server: localhost\n",
      "============================================================\n",
      "Debug: Server localhost has hostname:  and port: 0\n",
      "Server type: Local\n",
      "Connection status: Connected\n",
      "  Computing gradients locally (using GetGradients from server_communication)...\n",
      "  Local computation completed\n",
      "✓ Gradient computation successful!\n",
      "  Loss: 0.5\n",
      "  Gradients size: 3 elements\n",
      "  Sample gradients: 4.59312e+27, 4.58281e+30, 6.88852e+22\n",
      "\n",
      "============================================================\n",
      "Gradient testing with hardcoded values completed!\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'server_results': [{'server_name': 'gpu-server-1',\n",
       "   'is_local': False,\n",
       "   'is_connected': True,\n",
       "   'success': True,\n",
       "   'loss': 0.5,\n",
       "   'gradients_size': 3,\n",
       "   'gradients': [4.593116492825124e+27,\n",
       "    4.582813224188066e+30,\n",
       "    6.888519090641375e+22]},\n",
       "  {'server_name': 'localhost',\n",
       "   'is_local': True,\n",
       "   'is_connected': True,\n",
       "   'success': True,\n",
       "   'loss': 0.5,\n",
       "   'gradients_size': 3,\n",
       "   'gradients': [4.593116492825124e+27,\n",
       "    4.582813224188066e+30,\n",
       "    6.888519090641375e+22]}],\n",
       " 'total_servers': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_trainer.test_with_hardcoded_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                     download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                       shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanmarr/Documents/Subnautica_mod/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ryanmarr/Documents/Subnautica_mod/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-50 and modify for CIFAR-10\n",
    "model = resnet50(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()  # Remove maxpool as CIFAR-10 images are small\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # Change output to 10 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(\n",
    "#     project=\"big-model-example\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for idx, (input, target) in enumerate(trainloader):\n",
    "    print(idx)\n",
    "    if idx == 0:\n",
    "        i = input\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9.0974e-02,  1.3434e-02, -8.3491e-02,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 1.2974e-01,  7.1589e-02, -2.5336e-02,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 1.4913e-01,  1.4913e-01,  1.3434e-02,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          ...,\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00]],\n",
       "\n",
       "         [[ 7.6703e-04, -3.8567e-02, -1.5657e-01,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 5.9768e-02, -1.8900e-02, -1.3690e-01,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 7.9434e-02,  7.6703e-04, -1.1723e-01,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          ...,\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00]],\n",
       "\n",
       "         [[-1.3044e+00, -1.4605e+00, -1.4605e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-1.3044e+00, -1.3825e+00, -1.3825e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-1.2459e+00, -1.2459e+00, -1.2849e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          ...,\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5141e+00,  2.5141e+00,  2.5141e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 2.5141e+00,  2.5141e+00,  2.5141e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 2.5141e+00,  2.5141e+00,  2.5141e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          ...,\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00]],\n",
       "\n",
       "         [[ 2.5968e+00,  2.5968e+00,  2.5968e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 2.5968e+00,  2.5968e+00,  2.5968e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 2.5968e+00,  2.5968e+00,  2.5968e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          ...,\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00]],\n",
       "\n",
       "         [[ 2.7537e+00,  2.7537e+00,  2.7537e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [ 2.7537e+00,  2.7537e+00,  2.7537e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [ 2.7537e+00,  2.7537e+00,  2.7537e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          ...,\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          ...,\n",
       "          [ 1.7387e+00,  1.5836e+00,  1.1959e+00,  ...,  1.6030e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 1.7775e+00,  1.8744e+00,  1.9325e+00,  ...,  1.6999e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 1.8938e+00,  1.9519e+00,  1.9519e+00,  ...,  1.8162e+00,\n",
       "           -2.4291e+00, -2.4291e+00]],\n",
       "\n",
       "         [[-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          ...,\n",
       "          [ 1.8101e+00,  1.6724e+00,  1.3578e+00,  ...,  1.6724e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 1.8495e+00,  1.8495e+00,  1.8495e+00,  ...,  1.7708e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 1.9675e+00,  1.9675e+00,  1.9281e+00,  ...,  1.8888e+00,\n",
       "           -2.4183e+00, -2.4183e+00]],\n",
       "\n",
       "         [[-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          ...,\n",
       "          [ 1.9538e+00,  1.9538e+00,  1.7782e+00,  ...,  1.8367e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [ 2.0319e+00,  1.9538e+00,  1.9148e+00,  ...,  1.9343e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [ 2.1294e+00,  2.0514e+00,  1.9538e+00,  ...,  2.0514e+00,\n",
       "           -2.2214e+00, -2.2214e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.4291e+00, -3.1611e-01,  7.1589e-02,  ..., -8.3491e-02,\n",
       "           -4.3242e-01, -3.7426e-01],\n",
       "          [-2.4291e+00, -2.7734e-01,  3.2359e-01,  ...,  9.0974e-02,\n",
       "           -2.5796e-01, -2.1919e-01],\n",
       "          ...,\n",
       "          [-2.4291e+00, -1.4165e-01,  3.4298e-01,  ..., -2.7734e-01,\n",
       "           -2.3857e-01, -2.5336e-02],\n",
       "          [-2.4291e+00, -2.5796e-01,  1.4913e-01,  ..., -6.4565e-01,\n",
       "           -7.6196e-01, -4.9057e-01],\n",
       "          [-2.4291e+00, -8.0073e-01, -8.3950e-01,  ..., -1.0721e+00,\n",
       "           -1.9832e+00, -1.8281e+00]],\n",
       "\n",
       "         [[-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.4183e+00, -3.5324e-01, -2.7457e-01,  ..., -5.4990e-01,\n",
       "           -7.6624e-01, -7.4657e-01],\n",
       "          [-2.4183e+00, -3.3357e-01, -9.7567e-02,  ..., -5.1057e-01,\n",
       "           -7.6624e-01, -7.2691e-01],\n",
       "          ...,\n",
       "          [-2.4183e+00, -2.5490e-01, -1.5657e-01,  ..., -2.7457e-01,\n",
       "           -6.4824e-01, -6.2857e-01],\n",
       "          [-2.4183e+00, -3.3357e-01, -1.7623e-01,  ..., -4.9090e-01,\n",
       "           -9.4324e-01, -8.6457e-01],\n",
       "          [-2.4183e+00, -6.0891e-01, -8.0557e-01,  ..., -7.2691e-01,\n",
       "           -1.7889e+00, -1.7889e+00]],\n",
       "\n",
       "         [[-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-2.2214e+00, -2.5085e-01, -5.0449e-01,  ..., -9.7273e-01,\n",
       "           -1.1678e+00, -1.0898e+00],\n",
       "          [-2.2214e+00, -2.3134e-01, -3.2889e-01,  ..., -9.5322e-01,\n",
       "           -1.1483e+00, -1.0703e+00],\n",
       "          ...,\n",
       "          [-2.2214e+00, -1.3379e-01, -3.0938e-01,  ..., -2.8987e-01,\n",
       "           -9.7273e-01, -1.1288e+00],\n",
       "          [-2.2214e+00, -1.7281e-01, -2.5085e-01,  ..., -4.0694e-01,\n",
       "           -1.1288e+00, -1.1873e+00],\n",
       "          [-2.2214e+00, -2.3134e-01, -6.0204e-01,  ..., -4.6547e-01,\n",
       "           -1.6946e+00, -1.8312e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4172e+00,  2.4559e+00,  2.4753e+00,  ...,  2.3396e+00,\n",
       "            2.3009e+00,  2.2815e+00],\n",
       "          [ 2.4172e+00,  2.4753e+00,  2.4753e+00,  ...,  2.3590e+00,\n",
       "            2.3202e+00,  2.3202e+00],\n",
       "          [ 2.3784e+00,  2.4172e+00,  2.4172e+00,  ...,  2.3202e+00,\n",
       "            2.3009e+00,  2.2815e+00],\n",
       "          ...,\n",
       "          [-7.2319e-01, -8.3491e-02, -1.0527e+00,  ...,  2.0682e+00,\n",
       "            1.9519e+00,  1.9519e+00],\n",
       "          [-5.4873e-01, -1.6103e-01, -1.1690e+00,  ...,  2.0101e+00,\n",
       "            1.9519e+00,  1.9519e+00],\n",
       "          [-8.0073e-01, -4.7119e-01, -1.2272e+00,  ...,  1.9907e+00,\n",
       "            1.9325e+00,  1.9713e+00]],\n",
       "\n",
       "         [[ 2.4198e+00,  2.4591e+00,  2.4788e+00,  ...,  2.3608e+00,\n",
       "            2.3018e+00,  2.2428e+00],\n",
       "          [ 2.4198e+00,  2.4591e+00,  2.4591e+00,  ...,  2.3805e+00,\n",
       "            2.3215e+00,  2.2625e+00],\n",
       "          [ 2.3805e+00,  2.4001e+00,  2.4001e+00,  ...,  2.3608e+00,\n",
       "            2.3018e+00,  2.2428e+00],\n",
       "          ...,\n",
       "          [-7.6624e-01, -2.5490e-01, -1.1792e+00,  ...,  2.0265e+00,\n",
       "            1.9085e+00,  1.9281e+00],\n",
       "          [-5.8924e-01, -2.7457e-01, -1.3169e+00,  ...,  1.9871e+00,\n",
       "            1.8888e+00,  1.9085e+00],\n",
       "          [-8.2524e-01, -5.4990e-01, -1.3759e+00,  ...,  1.9478e+00,\n",
       "            1.9085e+00,  1.9085e+00]],\n",
       "\n",
       "         [[ 2.5781e+00,  2.6367e+00,  2.6757e+00,  ...,  2.5976e+00,\n",
       "            2.5391e+00,  2.4806e+00],\n",
       "          [ 2.5976e+00,  2.6757e+00,  2.6952e+00,  ...,  2.6367e+00,\n",
       "            2.5781e+00,  2.5391e+00],\n",
       "          [ 2.5586e+00,  2.6172e+00,  2.6367e+00,  ...,  2.6172e+00,\n",
       "            2.5586e+00,  2.5196e+00],\n",
       "          ...,\n",
       "          [-6.2155e-01, -1.5330e-01, -9.3371e-01,  ...,  2.2465e+00,\n",
       "            2.1489e+00,  2.1099e+00],\n",
       "          [-4.6547e-01, -1.7281e-01, -1.0508e+00,  ...,  2.1879e+00,\n",
       "            2.1099e+00,  2.1099e+00],\n",
       "          [-6.2155e-01, -3.8743e-01, -1.0898e+00,  ...,  2.1879e+00,\n",
       "            2.1099e+00,  2.1099e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 1.0021e+00,  9.6329e-01,  9.2452e-01,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [ 1.4091e+00,  1.0214e+00,  1.0021e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          ...,\n",
       "          [-2.0414e+00, -2.1189e+00, -2.2546e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.1189e+00, -2.3321e+00, -2.3321e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00],\n",
       "          [-2.0801e+00, -2.3903e+00, -2.3321e+00,  ..., -2.4291e+00,\n",
       "           -2.4291e+00, -2.4291e+00]],\n",
       "\n",
       "         [[-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 1.2004e+00,  1.2004e+00,  1.2398e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [ 1.5741e+00,  1.2201e+00,  1.2791e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          ...,\n",
       "          [-2.0839e+00, -2.1036e+00, -2.2413e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.2216e+00, -2.2806e+00, -2.3396e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00],\n",
       "          [-2.2216e+00, -2.3396e+00, -2.3396e+00,  ..., -2.4183e+00,\n",
       "           -2.4183e+00, -2.4183e+00]],\n",
       "\n",
       "         [[-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [ 1.4661e+00,  1.5051e+00,  1.5831e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [ 1.8172e+00,  1.5051e+00,  1.6026e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          ...,\n",
       "          [-1.8117e+00, -1.8312e+00, -1.7531e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-1.9287e+00, -2.0653e+00, -1.9287e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00],\n",
       "          [-1.8897e+00, -2.1434e+00, -1.9873e+00,  ..., -2.2214e+00,\n",
       "           -2.2214e+00, -2.2214e+00]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model with LeafTrainer...\n",
      "Model state extracted, size: 23574015 parameters\n",
      "Distributing model to 2 servers...\n",
      "Debug: Server gpu-server-1 has hostname: 174.93.255.152 and port: 56442\n",
      "Storing model on server: gpu-server-1\n",
      "✓ Model stored on server gpu-server-1 successfully\n",
      "Debug: Server localhost has hostname:  and port: 0\n",
      "Storing model on server: localhost\n",
      "✓ Model stored locally successfully\n",
      "Model registered successfully! Total models: 1\n"
     ]
    }
   ],
   "source": [
    "model_registered = leaf_trainer.register_model(model)\n",
    "# results\n",
    "# #input, target = trainloader[0]\n",
    "# optimizer = leaf_trainer.register_optimizer(optimizer)\n",
    "\n",
    "# outputs = model(input)\n",
    "# loss = criterion(outputs=outputs, target=target)\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering criterion with LeafTrainer...\n",
      "Criterion registered successfully! Total criteria: 1\n"
     ]
    }
   ],
   "source": [
    "criterion_registered = model_registered.register_criterion(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Server gpu-server-1 has hostname: 174.93.255.152 and port: 56442\n",
      "Error on server gpu-server-1: Forward pass failed: Server gpu-server-1 forward pass failed: Model with index 0 not found\n",
      "Debug: Server localhost has hostname:  and port: 0\n",
      "Error on server localhost: Forward pass failed: Model with index 0 not found locally\n",
      "Distributed forward completed: 0/2 servers successful\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: leaf._core.Criterion, arg0: object, arg1: object) -> object\n\nInvoked with: <leaf._core.Criterion object at 0x17f65fd30>; kwargs: outputs=False, target=tensor([2, 9, 1, 9, 5, 5, 8, 4, 2, 9, 9, 0, 0, 2, 9, 2, 4, 4, 5, 5, 7, 8, 8, 3,\n        9, 0, 1, 9, 1, 9, 0, 2, 9, 8, 6, 2, 5, 4, 4, 8, 0, 5, 2, 0, 7, 7, 6, 7,\n        5, 7, 3, 3, 2, 9, 7, 6, 2, 2, 5, 5, 3, 9, 8, 6, 8, 9, 2, 2, 9, 7, 6, 7,\n        5, 1, 9, 4, 4, 9, 6, 2, 6, 6, 9, 4, 5, 2, 5, 6, 2, 2, 8, 4, 6, 9, 3, 7,\n        3, 1, 2, 2, 2, 6, 7, 9, 6, 8, 5, 4, 4, 8, 6, 6, 2, 5, 2, 9, 5, 8, 0, 2,\n        6, 8, 0, 6, 3, 7, 8, 0])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m results = model_registered(i)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcriterion_registered\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: leaf._core.Criterion, arg0: object, arg1: object) -> object\n\nInvoked with: <leaf._core.Criterion object at 0x17f65fd30>; kwargs: outputs=False, target=tensor([2, 9, 1, 9, 5, 5, 8, 4, 2, 9, 9, 0, 0, 2, 9, 2, 4, 4, 5, 5, 7, 8, 8, 3,\n        9, 0, 1, 9, 1, 9, 0, 2, 9, 8, 6, 2, 5, 4, 4, 8, 0, 5, 2, 0, 7, 7, 6, 7,\n        5, 7, 3, 3, 2, 9, 7, 6, 2, 2, 5, 5, 3, 9, 8, 6, 8, 9, 2, 2, 9, 7, 6, 7,\n        5, 1, 9, 4, 4, 9, 6, 2, 6, 6, 9, 4, 5, 2, 5, 6, 2, 2, 8, 4, 6, 9, 3, 7,\n        3, 1, 2, 2, 2, 6, 7, 9, 6, 8, 5, 4, 4, 8, 6, 6, 2, 5, 2, 9, 5, 8, 0, 2,\n        6, 8, 0, 6, 3, 7, 8, 0])"
     ]
    }
   ],
   "source": [
    "results = model_registered(i)\n",
    "print(criterion_registered(outputs=results, target=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(i)\n",
    "print(criterion(outputs=results, target=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Batch: {batch_idx + 1} | Loss: {running_loss/(batch_idx + 1):.3f} | '\n",
    "                  f'Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    return running_loss/len(trainloader), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return test_loss/len(testloader), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "print('Starting training...')\n",
    "best_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train()\n",
    "    test_loss, test_acc = test()\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    print(f'\\nEpoch: {epoch + 1}/{num_epochs}')\n",
    "    print(f'Time: {time.time() - start_time:.2f}s')\n",
    "    print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        print('Saving best model...')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': test_acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        torch.save(state, 'best_model.pth')\n",
    "        best_acc = test_acc\n",
    "print('Training completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
